{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_7C7QTes2zh"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q transformers datasets evaluate accelerate huggingface_hub wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W0VQuSRKuoe5"
   },
   "outputs": [],
   "source": [
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments,\n",
    "                          DataCollatorWithPadding, Trainer, pipeline)\n",
    "import torch, wandb, evaluate, huggingface_hub\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGMg6CqltMPI"
   },
   "source": [
    "# Finetune BERT For Phishing Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk1bltt5t_L7"
   },
   "source": [
    "BERT is a model that pre-trains deep bidirectional representations from unlabeled text using masked language modeling and next sentence prediction objectives. It can be fine-tuned with just one additional output layer to create state-of-the-art models for various natural language processing tasks, such as text classification, token classification, question answering, and more. BERT is good for classification tasks as phishing classification because it can capture the context and semantics of the text from both left and right directions, and learn to predict the correct label based on the pre-trained knowledge. BERT also has a special [CLS] token that is used for classification tasks, which is trained to represent the whole input sequence and can be fed to a classifier layer. BERT has achieved impressive results on several text classification benchmarks, such as GLUE, SST-2, and CoLA.\n",
    "\n",
    "This project will show how to:\n",
    "\n",
    "- Finetune BERT on a custom phishing dataset to determine whether a text is phishing or benign.\n",
    "- Use the finetuned model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZHLXaFwvDEf"
   },
   "source": [
    "We have to login to HuggingFace account in order to retrieve BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcx5STGnvNKG"
   },
   "outputs": [],
   "source": [
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0kbTEbWvb7k"
   },
   "source": [
    "Also, to monitor metrics during evaluation, we can login to Wandb account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aVfvKWXvjdU"
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-U05llmu1QJ"
   },
   "source": [
    "## Load phishing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ7hXUmwvsbU"
   },
   "source": [
    "We're going to start loading the phishind dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QurS33CctTBf"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ealvaradob/phishing-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w8TZgD2vv7C"
   },
   "source": [
    "Let's see a sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsjRz0ozv0xL",
    "outputId": "a5b1e6cc-926f-472f-cdb7-30c38dfe91d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1, 'text': 'https://vpoasss-ne-inbex.gynsujh.cn/'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzfRzWo-v4oS"
   },
   "source": [
    "There are two fields:\n",
    "\n",
    "- `text`: Text that can contain URLs, HTML codes, mails, and SMS messages.\n",
    "- `label`: 0 for benign, 1 for phishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRpFrUQxwlPB"
   },
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OwJp421wnpP"
   },
   "source": [
    "The next step is to load a BERT tokenizer to preprocess the text field. BERT expects input data in a specific format, and the tokenizer is responsible for converting the text into that format. The tokenizer splits the text into tokens, which are the basic units of language that the model can understand. The tokenizer also adds special tokens, such as [CLS] and [SEP], to mark the beginning and the end of the text or the separation between two sentences. The tokenizer also converts the tokens into numerical indices that correspond to the vocabulary of the model. These indices are then fed to the model as inputs. By using the same tokenizer that was used to pre-train the model, you can ensure that the model can process the text correctly and produce meaningful outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y3tkCX8mv2yE"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_dOFBl-xghl"
   },
   "source": [
    "We will create a preprocessing function to tokenize `text` and truncate sequences to be no longer than BERT's maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "dfa74e1164aa42208d67b46d56928463",
      "40a97bc19de9410f937d811726ea99a1",
      "1de249f232ae4867a028df11b86b03f2",
      "2432de571c554c09810cefe4d8ba711c",
      "154eede815c74b138549da9daa0fa380",
      "e1a38ffb61a84147b8adb58a7853e975",
      "2e741453346a4519863b4add1cc3d94a",
      "63cd76338b88474aa88a66f71e72e929",
      "cfa96aa72f45429cb5fb8a38b996b99a",
      "13f30632ba2e474088a079d11536d72c",
      "b4a8ec5223634aaea1fd2ef1badb6343",
      "f6cd33238c804eaa9a9609831377358a",
      "b0cdc98e53044770944a5c12d36c956c",
      "7a80fe1a0d564ab48c4f219eb15dfa0b",
      "7338fe56beb34bc2b1fbe6262c146f84",
      "7b801ff108a04780ba31b388dbd9b9cf",
      "6e8c34eb3b384052a5efde6d66afffcf",
      "7ffd5d2827f64afb98ac8664a61f1213",
      "5a7d07ca18774c888ce1ed5edc5d1e6e",
      "2e790a3e31164d0bb1532910172b3931",
      "63098c742bae4351a17d34b8b3dde202",
      "6b8a0dece8684c66b5c69b4940d25a45"
     ]
    },
    "id": "CGBcVrMwxjs8",
    "outputId": "10847261-c78a-4bc0-dd9d-6758ea350587"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muMRuSwsxvM-"
   },
   "source": [
    "We will create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eFb2hYPTx1N4"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7YExvw3x-91"
   },
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVQCRd7MyJiJ"
   },
   "source": [
    "Including a metric during training is often helpful for evaluating your model's performance. For phishing detection, the most important metrics are:\n",
    "\n",
    "- **True-Positive Rate (TPR) or Recall** - This is the ratio of the number of phishing emails or websites that the model correctly identifies as phishing and the total number of phishing emails or websites. It measures how well the model can detect phishing attacks and avoid false negatives. A high TPR means that the model can catch most of the phishing attempts and protect the users from falling victim to them.\n",
    "\n",
    "- **False-Positive Rate (FPR)**: This is the ratio of the number of legitimate emails or websites that the model incorrectly identifies as phishing and the total number of legitimate emails or websites. It measures how often the model makes mistakes and flags benign messages or sites as malicious. A low FPR means that the model can avoid unnecessary alerts and reduce the user frustration and the security team workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "R_9lbpvAyGA8"
   },
   "outputs": [],
   "source": [
    "metrics = evaluate.combine([\"accuracy\", \"precision\", \"recall\", \"ealvaradob/false_positive_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eb017So3nJz"
   },
   "source": [
    "This function passes our predictions and labels to compute to calculate the accuracy, recall and FPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "soNxajXs3iWs"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  return metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOIn5sl34dwm"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfPBqHHs4jIF"
   },
   "source": [
    "Before we start training our model, we'll create a map of the expected ids to their labels with `id2label` and `label2id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w-08bi5s4f6o"
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"benign\", 1: \"phishing\"}\n",
    "label2id = {\"benign\": 0, \"phishing\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp219uyC_vtu"
   },
   "source": [
    "In addition, we'll start monitoring with Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u1Gri6Yc_7u7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mealvarado\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ealvarado/phishing-detection/wandb/run-20231227_144943-c79j52pi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi' target=\"_blank\">ruby-serenity-17</a></strong> to <a href='https://wandb.ai/ealvarado/BERT-FINETUNING' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ealvarado/BERT-FINETUNING' target=\"_blank\">https://wandb.ai/ealvarado/BERT-FINETUNING</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi' target=\"_blank\">https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6a143da740>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"BERT-FINETUNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx9L9OoX4rjK"
   },
   "source": [
    "Bring BERT base model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a6gUvTY1QYFL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-large-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TABeEr9zSmzO"
   },
   "source": [
    "Pre-trained base model achieves an accuracy of 51%, which is deficient. However, we can improve its performance by fine-tuning it on our dataset. To do that, we have to specify the training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "k2ejs78GQ_cc"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert-finetuned-phishing\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    torch_compile=True,\n",
    "    fp16=True,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='recall',\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "DrjSDRvI61AJ",
    "outputId": "e3c23cf8-d3fa-4fbc-b08c-b92fb97aef69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11598' max='11598' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11598/11598 42:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>False Positive Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.961916</td>\n",
       "      <td>0.958353</td>\n",
       "      <td>0.950845</td>\n",
       "      <td>0.030036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.134460</td>\n",
       "      <td>0.969093</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.953303</td>\n",
       "      <td>0.019428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.168286</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>0.963134</td>\n",
       "      <td>0.024341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarado/.local/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/ealvarado/.local/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/ealvarado/.local/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/ealvarado/.local/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11598, training_loss=0.09884800195981766, metrics={'train_runtime': 2599.746, 'train_samples_per_second': 71.371, 'train_steps_per_second': 4.461, 'total_flos': 1.7224450545564864e+17, 'train_loss': 0.09884800195981766, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVk4viPO_LDR"
   },
   "source": [
    "Once training is completed, we can share the model to the Hub with the `push_to_hub()` method so everyone can use our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508,
     "referenced_widgets": [
      "34b9b2153bb643e297d93b38a000470a",
      "44ea4a04d65b40b29619dcc76c649c1a",
      "c3f67458be6c4cf3b20ce3e710548651",
      "2f0ef52acb884c55ad471398ffcabe25",
      "9a16b78d2d8a4925bc9fe5b7728fef38",
      "b5a88810eaba43d6a40fba396d5e0ff9",
      "ea0c29d8f8c449289a725c76c32885d7",
      "b1fcd3925822459daa28453f0740aa2a"
     ]
    },
    "id": "qUwDdOjl_KPI",
    "outputId": "29f56018-bd77-42b9-8128-9beaff844045"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.013 MB of 0.015 MB uploaded\\r'), FloatProgress(value=0.87532732962892, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█</td></tr><tr><td>eval/false_positive_rate</td><td>█▁▄</td></tr><tr><td>eval/loss</td><td>▁▃█</td></tr><tr><td>eval/precision</td><td>▁█▅</td></tr><tr><td>eval/recall</td><td>▁▂█</td></tr><tr><td>eval/runtime</td><td>█▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▄█</td></tr><tr><td>eval/steps_per_second</td><td>▁▄█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▄▄▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97039</td></tr><tr><td>eval/false_positive_rate</td><td>0.02434</td></tr><tr><td>eval/loss</td><td>0.16829</td></tr><tr><td>eval/precision</td><td>0.9664</td></tr><tr><td>eval/recall</td><td>0.96313</td></tr><tr><td>eval/runtime</td><td>88.2346</td></tr><tr><td>eval/samples_per_second</td><td>175.283</td></tr><tr><td>eval/steps_per_second</td><td>10.959</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>11598</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0249</td></tr><tr><td>train/total_flos</td><td>1.7224450545564864e+17</td></tr><tr><td>train/train_loss</td><td>0.09885</td></tr><tr><td>train/train_runtime</td><td>2599.746</td></tr><tr><td>train/train_samples_per_second</td><td>71.371</td></tr><tr><td>train/train_steps_per_second</td><td>4.461</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-serenity-17</strong> at: <a href='https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi' target=\"_blank\">https://wandb.ai/ealvarado/BERT-FINETUNING/runs/c79j52pi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231227_144943-c79j52pi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.push_to_hub()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDrqQWCXCFrX"
   },
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjEhfKFhCH7n"
   },
   "source": [
    "Now that we've finetuned the model, we can use it for phishing detection! Consider this example text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVgni0L4CSS4"
   },
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Text: Dear hotmail user. We noticed a login to your Hotmail account \"\n",
    "          \"from an unrecognized device on Tuesday, August 15, 2023 (GMT-5) 7:32 A.M. \"\n",
    "          \"Lima, Peru. Was it you? If so, ignore the rest of this email. If it was not \"\n",
    "          \"you, follow the links below to keep your Hotmail account secure and \"\n",
    "          \"provide the necessary information to keep your account active. CLICK HERE.\"\n",
    "          \"Thank you, Hotmail Team.\"\n",
    "    \"\\nURL: https://ec-ec.squarespace.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwKNryPfEK8E"
   },
   "source": [
    "The simplest way to try out the finetuned model for phishing detection is to use it in a `pipeline()`. Instantiate a `pipeline` for text classification with your model, and pass your text to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226,
     "referenced_widgets": [
      "b6cdd39ca2ba4bf0a94dd7519088a2d8",
      "c140213433894d6c8f94ebb7bb776dc3",
      "c256fbd905eb4a0eaaf68e1ebb6e264b",
      "5f9e0c72ebfd41a19dd6d13d2384c4eb",
      "4d4601bc177248339d336e8d7efccb03",
      "ceccfb625c7646a19e644f5881dc0b3a",
      "3c2798be1bd247e1a0d81fe96d1e7b7d",
      "74d152c081014e7d8128a496ead3cc8c",
      "11ed66a861684161972bc0d6d1a86613",
      "61a7a4273324439288bb3be92af4cb4d",
      "f33b42c349f24908a4bd7c31b5613f98",
      "e1bf269940a1448198269d80542a5a5e",
      "85040f14fa63478e869179b3811cfd4b",
      "9e553b627e9d4c84bc55f2e3db40237b",
      "c90c019b073b427a9b8b36ef37c6df61",
      "67b79d4f7d7649b6a7403cf576070223",
      "5066852937104b228f770cdb05f7704f",
      "e8462d38aa7f4b00a771d4a9f612c495",
      "83f99bcda47d492b9e674feda3c29b27",
      "6055b1f73db14b9ab16b0789b315467b",
      "d5a2cccec0d04bd6af5ee1cb1e81c5bf",
      "5771adeaa73e423d979b6361851b69fb",
      "69900d15278f43e3ae78105e7110748b",
      "3240e6c7c0394ee58d5bd4eafd4ebaa3",
      "168eca20ee3d467885450a94640fb312",
      "0011febab30a4969aaf642100742afc7",
      "9224576b2fb041e3a05d7264e9d770a5",
      "859f12c5fab546de8996ed3b99510e97",
      "84018408896642e68adf48b090f88f3e",
      "b13aad66a1d844849ebaa93e6f7bd2dd",
      "fcf16778ab1f461fa3eaa5ea0db2e1cf",
      "784ec1c5695b462ca2915dfa95448938",
      "072df567ff634b26a9d864bec51fd95f",
      "40355a05321f447a99a9c45bf4edcb5b",
      "ee9fa37052b643aba678d69d5aaceec4",
      "05b91f70e2174d3480717c61d5cb5da1",
      "45370723ab0c414985d65651ee2cc25d",
      "9e5da71d0e3d4157ac52cccf7ddeae11",
      "e8a835bf41364e07aad6ba31e55c830a",
      "c60107ea5c78487c8a01441dd9d742cb",
      "c5de1da19b7e40bc8d3c653adb785ad5",
      "df60a3d2a40a4576890f697ee3dba86d",
      "b2679c6a8bc34f17b5eda643221dfc96",
      "55dd513885b84dafa9a2db7490ace922",
      "6bc1dbfd9f6e4d168ba9a4e211af24be",
      "a57cd1c446c947c6947734bc376bae2c",
      "1565b8e01aa249b992f2239f833ee8e7",
      "56b21e4cd3b74719b8caede424f2df7a",
      "858da3299cb34304b09c68c98d0a75c6",
      "14909ff363244e0c8837884f4be52b9a",
      "d3cc11aa2cee49ab8cf981494820745f",
      "75f4177678bc46d19c12b88eb144bdbb",
      "367bc84c2dd847848ffcc2ad0cebc5d9",
      "9840535506f24a39ab012674f25c3b44",
      "f2ee451a289b40b6b8f2840ca92e4fa0",
      "d7c752dd07ed46198bf2d2b6566b140d",
      "8ff70bb99fd94fb18a0d6e127055fa48",
      "bf71eccd2dc540c0ae31e2f18d525716",
      "3dde90b9723e432c9f47c50aa78e8657",
      "9946c16630194bcc8ea2e4b93e5e8bdf",
      "2cea8a94692a448f99044e1b8fb1fff2",
      "3d8159fafcf04102a321993d14b21a67",
      "cc0edea50b044205b5281d970c043ffd",
      "4fe95d8efab64f369fa256ce5e62fe57",
      "5c99e3d9f5fa41a0a21497bfe5278d70",
      "8b705f70adad43969509cb4ad62c703a"
     ]
    },
    "id": "XDPROsE_D14Y",
    "outputId": "c8ed264f-3205-4555-e533-9dcc13c046b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cdd39ca2ba4bf0a94dd7519088a2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/845 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bf269940a1448198269d80542a5a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69900d15278f43e3ae78105e7110748b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40355a05321f447a99a9c45bf4edcb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc1dbfd9f6e4d168ba9a4e211af24be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c752dd07ed46198bf2d2b6566b140d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'phishing', 'score': 0.9901213645935059}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"ealvaradob/bert-finetuned-phishing\")\n",
    "classifier(text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a9b76e8fad549279f8a7b9f3da0270f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0b6dc37d2ae44e92b576f541cc825af9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxModel",
      "state": {
       "description": "Add token as git credential?",
       "disabled": false,
       "layout": "IPY_MODEL_0a9b76e8fad549279f8a7b9f3da0270f",
       "style": "IPY_MODEL_9c89ebd265814be3b20ead42130d8aff",
       "value": true
      }
     },
     "0d1869bb2c88474baa8f1f01c710b278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3d7f2558e98643bf86183c936d6ad9be",
       "style": "IPY_MODEL_c8988025f5774ffa82ef696e6e48fa08",
       "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
      }
     },
     "10ea715b3ae747728cb5e8364a7050c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "118610b558094761be74adb247eb81cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "203a280a61c644a9b26abf752649315c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "22a3b107ee724d248f4dd54f88f4f6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_42e69a1dcc8a4dc6a3332d8127762ac6",
       "max": 1,
       "style": "IPY_MODEL_4feb8cfbd44f4f009d6daeefada559a0",
       "value": 1
      }
     },
     "266291c44bf24340ba5f49f5355a0abf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2c6ea34890684005b67b24302f3f1f0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_7861dfd69dd74aa4863178ccf5085d30",
       "style": "IPY_MODEL_8293924fe13240f9bcff9801a9368ac1",
       "value": "Your token has been saved to /home/ealvarado/.cache/huggingface/token"
      }
     },
     "2d8c624cf5ac46a98c33a7712127f7e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_4befbb6602fa4da1b13f8eff972d41b1",
       "style": "IPY_MODEL_3d899aed296f443c9a4f49ca297254df",
       "value": "Login successful"
      }
     },
     "3152251623a44de8b2142642f4f9098c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "31e8694b33414cbbbee347f6b4e9736d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "343e1f8c39954d48b198cccc9a7fd432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "PasswordModel",
      "state": {
       "description": "Token:",
       "layout": "IPY_MODEL_266291c44bf24340ba5f49f5355a0abf",
       "style": "IPY_MODEL_d8a5db8b2e53435abad1b8e8e7ece156"
      }
     },
     "3b5c127c73bd4969a09b7d748b1da889": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d7f2558e98643bf86183c936d6ad9be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3d899aed296f443c9a4f49ca297254df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "3efc48df4c0c4b40b840a8b4a1476f4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40867599d66b4781bf43d26b16b0488d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4245ad730e6f47e2ad9273a9b4b12c86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_8bc7b3282f2d49b6b362af65ad0cd2c3",
       "style": "IPY_MODEL_3152251623a44de8b2142642f4f9098c",
       "value": "Token is valid (permission: write)."
      }
     },
     "42e69a1dcc8a4dc6a3332d8127762ac6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "49b1b98600674ce6af1a82674aee3784": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_3efc48df4c0c4b40b840a8b4a1476f4e",
       "style": "IPY_MODEL_10ea715b3ae747728cb5e8364a7050c5"
      }
     },
     "4befbb6602fa4da1b13f8eff972d41b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4feb8cfbd44f4f009d6daeefada559a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "50c737caa3ae4cf5a4dda4a62f9e1e2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_79e6996ef2814d84b8906f072c871e06",
       "style": "IPY_MODEL_eb15048fab93494681a8e6e73b4065e9",
       "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
      }
     },
     "51230013cec740a2805647b13b055a7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "51c211d6834744b98202a1cc17103653": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Login",
       "layout": "IPY_MODEL_5bab208af83946ca8f142aaaa72c4dd4",
       "style": "IPY_MODEL_97352e184e4c4e73ab75f7a03232c554",
       "tooltip": null
      }
     },
     "5498d448cda74392adcab2ab388fc217": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "5bab208af83946ca8f142aaaa72c4dd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "69dfe0ac11774576b7d4a061d3c78a7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "7861dfd69dd74aa4863178ccf5085d30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "790d79c46557420a8aa9e024b7e8ae97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_203a280a61c644a9b26abf752649315c",
       "style": "IPY_MODEL_5498d448cda74392adcab2ab388fc217",
       "value": "0.029 MB of 0.029 MB uploaded\r"
      }
     },
     "79e6996ef2814d84b8906f072c871e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8293924fe13240f9bcff9801a9368ac1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "8bc7b3282f2d49b6b362af65ad0cd2c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "97352e184e4c4e73ab75f7a03232c554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ButtonStyleModel",
      "state": {
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "9c89ebd265814be3b20ead42130d8aff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "CheckboxStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a70d33be56404f06a97ad56f4d4d48ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af511c92bda24f17a56db586bcccc04e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_49b1b98600674ce6af1a82674aee3784",
        "IPY_MODEL_c891005b373d40a7895f78e3a8f7af84"
       ],
       "layout": "IPY_MODEL_ea18936dbd944a0e9413e874653d00a5"
      }
     },
     "bdd4604a6f434107bbfbb44ddc0a8ba5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_a70d33be56404f06a97ad56f4d4d48ef",
       "style": "IPY_MODEL_69dfe0ac11774576b7d4a061d3c78a7f",
       "value": "Your token has been saved in your configured git credential helpers (store)."
      }
     },
     "c798bd0dccb74205a810919c473c63bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_items": "center",
       "display": "flex",
       "flex_flow": "column",
       "width": "50%"
      }
     },
     "c891005b373d40a7895f78e3a8f7af84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_3b5c127c73bd4969a09b7d748b1da889",
       "max": 1,
       "style": "IPY_MODEL_31e8694b33414cbbbee347f6b4e9736d"
      }
     },
     "c8988025f5774ffa82ef696e6e48fa08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d51ba8625c6246058ee0f47aa0bffddb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_40867599d66b4781bf43d26b16b0488d",
       "style": "IPY_MODEL_51230013cec740a2805647b13b055a7a",
       "value": "Connecting..."
      }
     },
     "d8a5db8b2e53435abad1b8e8e7ece156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TextStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dfb1abc99949460b9d49a1852609083b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4245ad730e6f47e2ad9273a9b4b12c86",
        "IPY_MODEL_bdd4604a6f434107bbfbb44ddc0a8ba5",
        "IPY_MODEL_2c6ea34890684005b67b24302f3f1f0f",
        "IPY_MODEL_2d8c624cf5ac46a98c33a7712127f7e4"
       ],
       "layout": "IPY_MODEL_c798bd0dccb74205a810919c473c63bb"
      }
     },
     "ea18936dbd944a0e9413e874653d00a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb15048fab93494681a8e6e73b4065e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
